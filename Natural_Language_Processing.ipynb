{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are many applications for NLP models.  \n",
    "* A well-known model is the Bag of Words model.  It is used to preprocess text.  \n",
    "* In this part we will learn:  \n",
    "1. Clean text to prepare them for ML models.  \n",
    "2. Create a bag of words model.  \n",
    "3. Apply ML models on the bag of words model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP INTUITION**  \n",
    "* Types of Natural Language Processing   \n",
    "* Classical vs Deep Learning Models  \n",
    "* Bag of Words Model  \n",
    "* We will not be covering Seq2Seq or Chatbots  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of Natural Language Processing**  \n",
    "* Where Deep Learning intersects with NLP  = DNLP = Our focus  \n",
    "* Subset of DNLP = Seq2Seq = most cutting edge NLP  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical vs Deep Learning Models**  \n",
    "EXAMPLES:  \n",
    "* If/Else (Chatbot) != DL  \n",
    "* Audio Frequency Components Analysis (Speech Recognition) != DL  ; mathematical calculations around observed frequencies to library frequencies and trying to match up  \n",
    "* Bag of Words Model (Classification) != DL  (but possible for it to sit in DL realm)  \n",
    "* CNN for text recognition (Classification) == DNLP ; \n",
    "* Seq2Seq (many applications) == DNLP  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BAG OF WORDS MODEL**  \n",
    "* Begin:  Create a Yes/No response.  \n",
    "* 20,000 words are columns ; enter number of times each word shows up per entry (row)  \n",
    "* Results in a sparse vector/matrix  \n",
    "* Need to start with Training data : text along with actual yes/no response  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Files are .tsv (Tab Separated Values) instead of typical .csv files - since commas are generally a part of our text.  \n",
    "* Not likely to be tabs in text (especially reviews - tab will move you to the next entry).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text <- read.delim('Restaurant_Reviews.tsv', quote = '', stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>2</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000    2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Need to create a corpus (Collection of Writings)  \n",
    "* Convert all text to lower case to avoid duplicates  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Wow... Loved this place.'"
      ],
      "text/latex": [
       "'Wow... Loved this place.'"
      ],
      "text/markdown": [
       "'Wow... Loved this place.'"
      ],
      "text/plain": [
       "[1] \"Wow... Loved this place.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'for 40 bucks a head, i really expect better food.'"
      ],
      "text/latex": [
       "'for 40 bucks a head, i really expect better food.'"
      ],
      "text/markdown": [
       "'for 40 bucks a head, i really expect better food.'"
      ],
      "text/plain": [
       "[1] \"for 40 bucks a head, i really expect better food.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'wow... loved this place.'"
      ],
      "text/latex": [
       "'wow... loved this place.'"
      ],
      "text/markdown": [
       "'wow... loved this place.'"
      ],
      "text/plain": [
       "[1] \"wow... loved this place.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'for 40 bucks a head, i really expect better food.'"
      ],
      "text/latex": [
       "'for 40 bucks a head, i really expect better food.'"
      ],
      "text/markdown": [
       "'for 40 bucks a head, i really expect better food.'"
      ],
      "text/plain": [
       "[1] \"for 40 bucks a head, i really expect better food.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'wow... loved this place.'"
      ],
      "text/latex": [
       "'wow... loved this place.'"
      ],
      "text/markdown": [
       "'wow... loved this place.'"
      ],
      "text/plain": [
       "[1] \"wow... loved this place.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'for  bucks a head, i really expect better food.'</span>"
      ],
      "text/latex": [
       "'for  bucks a head, i really expect better food.'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'for  bucks a head, i really expect better food.'</span>"
      ],
      "text/plain": [
       "[1] \"for  bucks a head, i really expect better food.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'wow loved this place'"
      ],
      "text/latex": [
       "'wow loved this place'"
      ],
      "text/markdown": [
       "'wow loved this place'"
      ],
      "text/plain": [
       "[1] \"wow loved this place\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'for  bucks a head i really expect better food'</span>"
      ],
      "text/latex": [
       "'for  bucks a head i really expect better food'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'for  bucks a head i really expect better food'</span>"
      ],
      "text/plain": [
       "[1] \"for  bucks a head i really expect better food\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'wow loved  place'</span>"
      ],
      "text/latex": [
       "'wow loved  place'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'wow loved  place'</span>"
      ],
      "text/plain": [
       "[1] \"wow loved  place\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'  bucks  head  really expect better food'</span>"
      ],
      "text/latex": [
       "'  bucks  head  really expect better food'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'  bucks  head  really expect better food'</span>"
      ],
      "text/plain": [
       "[1] \"  bucks  head  really expect better food\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tm)\n",
    "library(SnowballC)\n",
    "\n",
    "corpus <- VCorpus(VectorSource(data.text$Review))\n",
    "\n",
    "as.character(corpus[[1]])\n",
    "as.character(corpus[[841]])\n",
    "\n",
    "corpus <- tm_map(corpus, content_transformer(tolower))\n",
    "\n",
    "as.character(corpus[[1]])\n",
    "as.character(corpus[[841]])\n",
    "\n",
    "corpus <- tm_map(corpus, removeNumbers)\n",
    "\n",
    "as.character(corpus[[1]])\n",
    "as.character(corpus[[841]])\n",
    "\n",
    "corpus <- tm_map(corpus, removePunctuation)\n",
    "\n",
    "as.character(corpus[[1]])\n",
    "as.character(corpus[[841]])\n",
    "\n",
    "\n",
    "corpus <- tm_map(corpus, removeWords, stopwords())\n",
    "\n",
    "as.character(corpus[[1]])\n",
    "as.character(corpus[[841]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**  \n",
    "* Getting to the root of each word - remove multiple tenses and keep only single tense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'wow love place'"
      ],
      "text/latex": [
       "'wow love place'"
      ],
      "text/markdown": [
       "'wow love place'"
      ],
      "text/plain": [
       "[1] \"wow love place\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'buck head realli expect better food'"
      ],
      "text/latex": [
       "'buck head realli expect better food'"
      ],
      "text/markdown": [
       "'buck head realli expect better food'"
      ],
      "text/plain": [
       "[1] \"buck head realli expect better food\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus <- tm_map(corpus, stemDocument)\n",
    "\n",
    "as.character(corpus[[1]])\n",
    "as.character(corpus[[841]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove multiple spaces - only keep single space:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'wow love place'"
      ],
      "text/latex": [
       "'wow love place'"
      ],
      "text/markdown": [
       "'wow love place'"
      ],
      "text/plain": [
       "[1] \"wow love place\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'buck head realli expect better food'"
      ],
      "text/latex": [
       "'buck head realli expect better food'"
      ],
      "text/markdown": [
       "'buck head realli expect better food'"
      ],
      "text/plain": [
       "[1] \"buck head realli expect better food\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus <- tm_map(corpus, stripWhitespace)\n",
    "\n",
    "as.character(corpus[[1]])\n",
    "as.character(corpus[[841]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE THE BAG OF WORDS MODEL**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<DocumentTermMatrix (documents: 1000, terms: 1577)>>\n",
       "Non-/sparse entries: 5435/1571565\n",
       "Sparsity           : 100%\n",
       "Maximal term length: 32\n",
       "Weighting          : term frequency (tf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtm <- DocumentTermMatrix(corpus)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NOTE:  Sparsity is 100%  \n",
    "* We are going to apply additional cleanup to our corpus to reduce sparsity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<DocumentTermMatrix (documents: 1000, terms: 691)>>\n",
       "Non-/sparse entries: 4549/686451\n",
       "Sparsity           : 99%\n",
       "Maximal term length: 12\n",
       "Weighting          : term frequency (tf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtm <- removeSparseTerms(dtm, 0.999)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOW TO APPLY CLASSIFICATION MODEL TO OUR DOCUMENT TERM MATRIX (DTM)**  \n",
    "* We will use random forest classification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>691</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 691\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 691\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000  691"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset <- as.data.frame(as.matrix(dtm))\n",
    "dim(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can see from the above:  1,000 reviews with 691 words left after our data prep.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>692</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 692\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 692\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000  692"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset$Liked <- data.text$Liked\n",
    "dim(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n"
     ]
    }
   ],
   "source": [
    "# Encoding the target feature as factor\n",
    "dataset$Liked = factor(dataset$Liked, levels = c(0, 1))\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "# install.packages('caTools')\n",
    "library(caTools)\n",
    "set.seed(123)\n",
    "split = sample.split(dataset$Liked, SplitRatio = 0.8)\n",
    "training_set = subset(dataset, split == TRUE)\n",
    "test_set = subset(dataset, split == FALSE)\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "# install.packages('randomForest')\n",
    "library(randomForest)\n",
    "classifier = randomForest(x = training_set[-692],\n",
    "                          y = training_set$Liked,\n",
    "                          ntree = 10)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = predict(classifier, newdata = test_set[-692])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = table(test_set[, 692], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   y_pred\n",
       "     0  1\n",
       "  0 82 18\n",
       "  1 23 77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HOMEWORK**  \n",
    "* Run the other classification models we covered.  \n",
    "* Evaluate the performance of each of these models.  \n",
    "* Use metrics in addition to accuracy:  \n",
    "* Precision = TP/(TP + FP)  \n",
    "* Recall = TP/(TP + FN)  \n",
    "* F1 Score = 2 * Precision * Recall/(Precision + Recall)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

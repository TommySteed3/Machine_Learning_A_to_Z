{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVOLUTIONAL NEURAL NETWORKS**  \n",
    "* Gaining in popularity much more quickly than ANN.  \n",
    "* Used for IMAGE RECOGINITION:  self-driving cars ; photo recognition ; etc  \n",
    "STEPS:  \n",
    "1. Convolution  \n",
    "2. Max Pooling  \n",
    "3. Flattening  \n",
    "4. Full Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVOLUTION**  \n",
    "* CONVOLUTION FUNCTION:  (f*g)(t) def/==  Integral(-INf to +INF) f(tau)g(t - tau) dtau  \n",
    "* This is a common function used in many fields  \n",
    "* Good Resource: \"Introduction to Convolutional Neural Networks\" Jianxin Wu  \n",
    "* Input Image Convolution Feature Detector (usually 3x3 but can vary)  = Feature Map  \n",
    "* Above step is matrix multiplication by successive 3x3 selections from the input image against same feature detector  \n",
    "* Feature Map = Convolved Feature  \n",
    "* What is Feature Map?  For one thing - dimensionality is reduced from original image ; the larger the stride - the more the dimension reduction (stride = how much you move between successive 3x3 selections above).  \n",
    "![](convolution.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 4 1s in the Feature detector - this is the value for a perfect match - see that in Feature Map.  \n",
    "* Create several feature maps.  \n",
    "* Key Takeaway: Purpose of a convolution is to find features in your image using the feature detector ; Put them in a Feture Map (this preserves the spatial relationships between pixels) ;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU Layer**  \n",
    "* ReLU = Rectified Linear Units  \n",
    "* Apply rectifier function to our Feature Maps  \n",
    "* Rectifier Function: chi(x) = max(x,0)  ; want to increase non-linearity in our network  ; images are highly non-linear  \n",
    "* Part of the way rectifier accomplishes this is by removing negative values ; highly computational for a better understanding  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Resource: \"Understanding Convolutional Neural Networks with a Mathematical Model\" by CC Jay Kuo  \n",
    "* Resource: \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\"  by Kaiming He et al.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAX POOLING**  \n",
    "* Deal with variations - like rotated - different placement - facing different directions - etc  \n",
    "* Spatial consistency / placement was addressed already with Feature Mapping  \n",
    "* Starts with the Feature Map (so you have already applied convolution)  \n",
    "* Various types of pooling - we are looking at MAX pooling  \n",
    "* Go through segments of feature map (2x2s for example) and take max value in the segment - map to Pooled Feature Map  \n",
    "* Start with top left corner and segment whatever selected size is.  Move to the right by stride size ; use partial segment if you go over the edge of the Feature Map.  \n",
    "* Keeping features by capturing max - but reducing volume substantially - reduces overfitting  \n",
    "* Parameters such as:  Max Pooling (as opposed to Mean Pooling etc) ; Size of Segments (2x2 etc) ; Size of Strides (1,, 2, etc)  \n",
    "* Remember: we have multiple convolution layers ; apply max pooling to each - results in multiple Pooling Layers  \n",
    "* RESOURCE: \"Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition\"  by Dominik Scherer  \n",
    "* Nice interactive examples:  https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FLATTENING**  \n",
    "* Take your Pooled Feature Map and flatten it into a column with row 1 on top - then row 2 - etc  \n",
    "* Serves as an input layer for a future ANN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FULL CONNECTION**  \n",
    "* Applying an ANN to the results of our Flattening  \n",
    "* Refer to Hidden Layers as Fully Connected Layers - with ANN they don't have to be fully connected - but they do have to be fully connected with CNNs  \n",
    "* Final layer of this ANN is a series of nodes that have values (example is 0-1) that indicate how confident that node is that it detected its respective feature.  This info is passed onto all possible outputs.  \n",
    "* Means different things to different options.  Example - trunk being detected with value of 1 - is positive for class elephant - and negative for cat.  This is determined by final weightings on synapses? - connections from final layer to output options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARY**  \n",
    "* Start with Input Image  \n",
    "* Apply Feature Detectors (Filters) to create Feature Maps - this comprises our convolutional layer  \n",
    "* On top of Convolutional Layer - Apply ReLU (Rectified Linear Unit) - to remove linearity  \n",
    "* Applied Pooling Layer to Feature Map (Convoluted Layer) - Main purpose is spatial invariance (rotated images etc) - also reduces size and avoid overfitting    \n",
    "* Flatten all pooled images into column of values - input to ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RESOURCE: \"The 9 Deep Learning Papers You Need to Know About (Understanding CNNs Part 3)\"  Adit Desphande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOFTMAX AND CROSS-ENTROPY FUNCTIONS**  \n",
    "* Apply to final output of CNN so that values (which are not connected) sum to 1  \n",
    "* fj(z) = exp(z)* j / Sumk(exp(z) * k  ; Generalization of the logistic function  \n",
    "* Cross Entropy Function: Li = -log(exp(fsubysubi) / Sumj(exp(fsubj))  ; H(p,q) = -Sumx(p(x)logq(x)  \n",
    "* Idea of Cross Entropy:  Cost Function (better than MSE which we used before) ; Better option after applying Soft Max  \n",
    "* Now we refer to this as Loss Function rather than Cost Function - similar concept: THINGS WE WANT TO MINIMIZE!  \n",
    "![](Cross_Entropy.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above calcs were done by hand/XLS - not very complicated - Cross-Entropy is just another Loss Function    \n",
    "* Why Cross Entropy over MSE?  Several advantages that are not so obvious (especially in a simple example like the one above)  \n",
    "* Very low MSE values can cause issues with Gradient Descent (Cross Entropy addresses with log) - ie - log is better than square for Loss Functions - especially with values around 0 (common for 0-1 predictions)  \n",
    "* Cross Entropy only for Classification with Soft Max ; Still use MSE with Regression problems  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RESOURCES: \"A Friendly Introduction to Cross-Entropy Loss\" by Rob DiPietro  \n",
    "* RESOURCES: \"How to implement a neural network Intermezzo 2\" by Peter Roelants  (HEAVY MATH)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
